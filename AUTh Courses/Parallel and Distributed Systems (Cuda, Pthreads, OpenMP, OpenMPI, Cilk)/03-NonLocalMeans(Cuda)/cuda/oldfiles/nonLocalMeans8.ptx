//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21124049
// Cuda compilation tools, release 8.0, V8.0.44
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_20
.address_size 64

	// .globl	_Z3nlmPKfPfif
.extern .func __assertfail
(
	.param .b64 __assertfail_param_0,
	.param .b64 __assertfail_param_1,
	.param .b32 __assertfail_param_2,
	.param .b64 __assertfail_param_3,
	.param .b64 __assertfail_param_4
)
;
.const .align 4 .b8 gaussDistW[196];
.global .align 1 .b8 __T20[45] = {118, 111, 105, 100, 32, 110, 108, 109, 40, 99, 111, 110, 115, 116, 32, 102, 108, 111, 97, 116, 32, 42, 44, 32, 102, 108, 111, 97, 116, 32, 42, 44, 32, 105, 110, 116, 44, 32, 102, 108, 111, 97, 116, 41, 0};
// _Z3nlmPKfPfif$__cuda_local_var_16163_32_non_const_blockImg has been demoted
// _Z3nlmPKfPfif$__cuda_local_var_16164_32_non_const_foreignBlockImg has been demoted
.global .align 1 .b8 $str[17] = {71, 83, 90, 32, 61, 61, 32, 103, 114, 105, 100, 68, 105, 109, 46, 120, 0};
.global .align 1 .b8 $str1[18] = {110, 111, 110, 76, 111, 99, 97, 108, 77, 101, 97, 110, 115, 56, 46, 99, 117, 0};
.global .align 1 .b8 $str2[19] = {66, 83, 90, 48, 32, 61, 61, 32, 98, 108, 111, 99, 107, 68, 105, 109, 46, 120, 0};

.visible .entry _Z3nlmPKfPfif(
	.param .u64 _Z3nlmPKfPfif_param_0,
	.param .u64 _Z3nlmPKfPfif_param_1,
	.param .u32 _Z3nlmPKfPfif_param_2,
	.param .f32 _Z3nlmPKfPfif_param_3
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<143>;
	.reg .b32 	%r<96>;
	.reg .b64 	%rd<87>;
	// demoted variable
	.shared .align 4 .b8 _Z3nlmPKfPfif$__cuda_local_var_16163_32_non_const_blockImg[1600];
	// demoted variable
	.shared .align 4 .b8 _Z3nlmPKfPfif$__cuda_local_var_16164_32_non_const_foreignBlockImg[1600];

	ld.param.u64 	%rd16, [_Z3nlmPKfPfif_param_0];
	ld.param.u64 	%rd17, [_Z3nlmPKfPfif_param_1];
	ld.param.f32 	%f32, [_Z3nlmPKfPfif_param_3];
	mov.u32 	%r28, %nctaid.x;
	setp.eq.s32	%p1, %r28, 4;
	@%p1 bra 	BB0_2;

	mov.u64 	%rd18, $str;
	cvta.global.u64 	%rd19, %rd18;
	mov.u64 	%rd20, $str1;
	cvta.global.u64 	%rd21, %rd20;
	mov.u64 	%rd22, __T20;
	cvta.global.u64 	%rd23, %rd22;
	mov.u32 	%r29, 93;
	mov.u64 	%rd24, 1;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd19;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd21;
	.param .b32 param2;
	st.param.b32	[param2+0], %r29;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd23;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd24;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 0

BB0_2:
	mov.u32 	%r30, %ntid.x;
	setp.eq.s32	%p2, %r30, 16;
	@%p2 bra 	BB0_4;

	mov.u64 	%rd25, $str2;
	cvta.global.u64 	%rd26, %rd25;
	mov.u64 	%rd27, $str1;
	cvta.global.u64 	%rd28, %rd27;
	mov.u64 	%rd29, __T20;
	cvta.global.u64 	%rd30, %rd29;
	mov.u32 	%r31, 94;
	mov.u64 	%rd31, 1;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd28;
	.param .b32 param2;
	st.param.b32	[param2+0], %r31;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd30;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd31;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 1

BB0_4:
	cvta.to.global.u64 	%rd1, %rd16;
	mov.u32 	%r32, %ctaid.y;
	mov.u32 	%r33, %ctaid.x;
	shl.b32 	%r34, %r33, 4;
	mad.lo.s32 	%r1, %r32, 1088, %r34;
	mov.u32 	%r2, %tid.y;
	shl.b32 	%r35, %r2, 4;
	mov.u32 	%r3, %tid.x;
	add.s32 	%r83, %r35, %r3;

BB0_5:
	setp.gt.s32	%p3, %r83, 399;
	@%p3 bra 	BB0_7;

	mul.hi.s32 	%r36, %r83, 1717986919;
	shr.s32 	%r37, %r36, 3;
	shr.u32 	%r38, %r36, 31;
	add.s32 	%r39, %r37, %r38;
	mul.lo.s32 	%r40, %r39, 20;
	sub.s32 	%r41, %r83, %r40;
	add.s32 	%r42, %r1, %r41;
	mad.lo.s32 	%r43, %r39, 68, %r42;
	mul.wide.s32 	%rd32, %r43, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f33, [%rd33];
	mul.wide.s32 	%rd34, %r41, 80;
	mov.u64 	%rd35, _Z3nlmPKfPfif$__cuda_local_var_16163_32_non_const_blockImg;
	add.s64 	%rd36, %rd35, %rd34;
	mul.wide.s32 	%rd37, %r39, 4;
	add.s64 	%rd38, %rd36, %rd37;
	st.shared.f32 	[%rd38], %f33;

BB0_7:
	add.s32 	%r83, %r83, 256;
	setp.lt.s32	%p4, %r83, 400;
	@%p4 bra 	BB0_5;

	bar.sync 	0;
	cvt.u64.u32	%rd2, %r2;
	mov.u32 	%r44, 0;
	mov.f32 	%f141, 0f00000000;
	mov.f32 	%f140, %f141;
	mov.f32 	%f139, %f141;
	mov.u32 	%r86, %r44;

BB0_9:
	mov.u32 	%r85, %r44;

BB0_10:
	mov.u32 	%r8, %r85;
	mul.wide.s32 	%rd40, %r8, 4;
	mul.wide.s32 	%rd41, %r86, 80;
	add.s64 	%rd83, %rd41, %rd40;
	mov.f32 	%f138, 0f00000000;
	mov.u64 	%rd84, gaussDistW;
	mov.u32 	%r87, -5;
	mov.u32 	%r94, %r3;

BB0_11:
	mul.wide.u32 	%rd42, %r94, 80;
	mov.u64 	%rd43, _Z3nlmPKfPfif$__cuda_local_var_16163_32_non_const_blockImg;
	add.s64 	%rd44, %rd43, %rd42;
	shl.b64 	%rd45, %rd2, 2;
	add.s64 	%rd46, %rd44, %rd45;
	add.s64 	%rd47, %rd43, %rd83;
	ld.shared.f32 	%f38, [%rd47];
	ld.shared.f32 	%f39, [%rd46];
	sub.f32 	%f40, %f39, %f38;
	mul.f32 	%f41, %f40, %f40;
	ld.const.f32 	%f42, [%rd84+32];
	fma.rn.f32 	%f43, %f42, %f41, %f138;
	ld.shared.f32 	%f44, [%rd47+4];
	ld.shared.f32 	%f45, [%rd46+4];
	sub.f32 	%f46, %f45, %f44;
	mul.f32 	%f47, %f46, %f46;
	ld.const.f32 	%f48, [%rd84+60];
	fma.rn.f32 	%f49, %f48, %f47, %f43;
	ld.shared.f32 	%f50, [%rd47+8];
	ld.shared.f32 	%f51, [%rd46+8];
	sub.f32 	%f52, %f51, %f50;
	mul.f32 	%f53, %f52, %f52;
	ld.const.f32 	%f54, [%rd84+88];
	fma.rn.f32 	%f55, %f54, %f53, %f49;
	ld.shared.f32 	%f56, [%rd47+12];
	ld.shared.f32 	%f57, [%rd46+12];
	sub.f32 	%f58, %f57, %f56;
	mul.f32 	%f59, %f58, %f58;
	ld.const.f32 	%f60, [%rd84+116];
	fma.rn.f32 	%f61, %f60, %f59, %f55;
	ld.shared.f32 	%f62, [%rd47+16];
	ld.shared.f32 	%f63, [%rd46+16];
	sub.f32 	%f64, %f63, %f62;
	mul.f32 	%f65, %f64, %f64;
	ld.const.f32 	%f66, [%rd84+144];
	fma.rn.f32 	%f138, %f66, %f65, %f61;
	add.s64 	%rd84, %rd84, 4;
	add.s32 	%r94, %r94, 1;
	add.s64 	%rd83, %rd83, 80;
	add.s32 	%r87, %r87, 1;
	setp.ne.s32	%p5, %r87, 0;
	@%p5 bra 	BB0_11;

	neg.f32 	%f69, %f138;
	div.rn.f32 	%f70, %f69, %f32;
	mul.f32 	%f71, %f70, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f72, %f71;
	mov.f32 	%f73, 0fBF317200;
	fma.rn.f32 	%f74, %f72, %f73, %f70;
	mov.f32 	%f75, 0fB5BFBE8E;
	fma.rn.f32 	%f76, %f72, %f75, %f74;
	mul.f32 	%f68, %f76, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f67,%f68;
	// inline asm
	add.f32 	%f77, %f72, 0f00000000;
	ex2.approx.f32 	%f78, %f77;
	mul.f32 	%f79, %f67, %f78;
	setp.lt.f32	%p6, %f70, 0fC2D20000;
	selp.f32	%f80, 0f00000000, %f79, %p6;
	setp.gt.f32	%p7, %f70, 0f42D20000;
	selp.f32	%f81, 0f7F800000, %f80, %p7;
	setp.neu.f32	%p8, %f81, 0f3F800000;
	setp.lt.f32	%p9, %f139, %f81;
	and.pred  	%p10, %p8, %p9;
	selp.f32	%f139, %f81, %f139, %p10;
	add.f32 	%f141, %f81, %f141;
	add.s32 	%r47, %r86, 2;
	add.s32 	%r48, %r8, 2;
	mul.wide.s32 	%rd48, %r47, 80;
	add.s64 	%rd50, %rd43, %rd48;
	mul.wide.s32 	%rd51, %r48, 4;
	add.s64 	%rd52, %rd50, %rd51;
	ld.shared.f32 	%f82, [%rd52];
	fma.rn.f32 	%f140, %f81, %f82, %f140;
	add.s32 	%r13, %r8, 1;
	setp.lt.s32	%p11, %r13, 16;
	mov.u32 	%r85, %r13;
	@%p11 bra 	BB0_10;

	add.s32 	%r86, %r86, 1;
	setp.lt.s32	%p12, %r86, 16;
	mov.u16 	%rs5, 0;
	@%p12 bra 	BB0_9;

	mov.u16 	%rs12, %rs5;

BB0_15:
	mov.u16 	%rs11, %rs5;

BB0_16:
	mov.u16 	%rs2, %rs11;
	cvt.u32.u16	%r49, %rs12;
	cvt.s32.s8 	%r50, %r49;
	setp.ne.s32	%p13, %r33, %r50;
	cvt.u32.u16	%r53, %rs2;
	cvt.s32.s8 	%r15, %r53;
	setp.ne.s32	%p14, %r32, %r15;
	or.pred  	%p15, %p13, %p14;
	@!%p15 bra 	BB0_27;
	bra.uni 	BB0_17;

BB0_17:
	cvt.s16.s8 	%rs7, %rs12;
	mul.wide.s16 	%r54, %rs7, 16;
	mad.lo.s32 	%r16, %r15, 1088, %r54;
	mov.u32 	%r57, %tid.x;
	add.s32 	%r88, %r35, %r57;

BB0_18:
	setp.gt.s32	%p16, %r88, 399;
	@%p16 bra 	BB0_20;

	mul.hi.s32 	%r58, %r88, 1717986919;
	shr.s32 	%r59, %r58, 3;
	shr.u32 	%r60, %r58, 31;
	add.s32 	%r61, %r59, %r60;
	mul.lo.s32 	%r62, %r61, 20;
	sub.s32 	%r63, %r88, %r62;
	add.s32 	%r64, %r16, %r63;
	mad.lo.s32 	%r65, %r61, 68, %r64;
	mul.wide.s32 	%rd54, %r65, 4;
	add.s64 	%rd55, %rd1, %rd54;
	ld.global.f32 	%f83, [%rd55];
	mul.wide.s32 	%rd56, %r63, 80;
	mov.u64 	%rd57, _Z3nlmPKfPfif$__cuda_local_var_16164_32_non_const_foreignBlockImg;
	add.s64 	%rd58, %rd57, %rd56;
	mul.wide.s32 	%rd59, %r61, 4;
	add.s64 	%rd60, %rd58, %rd59;
	st.shared.f32 	[%rd60], %f83;

BB0_20:
	add.s32 	%r88, %r88, 256;
	setp.lt.s32	%p17, %r88, 400;
	@%p17 bra 	BB0_18;

	bar.sync 	0;
	mov.u32 	%r66, 0;
	mov.u32 	%r91, %r66;

BB0_22:
	mul.wide.s32 	%rd8, %r91, 80;
	add.s32 	%r68, %r91, 2;
	cvt.s64.s32	%rd9, %r68;
	mov.u32 	%r90, %r66;

BB0_23:
	mov.u32 	%r21, %r90;
	mul.wide.s32 	%rd62, %r21, 4;
	add.s64 	%rd85, %rd8, %rd62;
	add.s32 	%r22, %r21, 1;
	add.s32 	%r70, %r21, 2;
	cvt.s64.s32	%rd11, %r70;
	mov.f32 	%f142, 0f00000000;
	mov.u64 	%rd86, gaussDistW;
	mov.u32 	%r95, -5;
	mov.u32 	%r93, %r3;

BB0_24:
	mov.u32 	%r23, %r93;
	mul.wide.u32 	%rd63, %r23, 80;
	add.s64 	%rd65, %rd43, %rd63;
	add.s64 	%rd67, %rd65, %rd45;
	mov.u64 	%rd68, _Z3nlmPKfPfif$__cuda_local_var_16164_32_non_const_foreignBlockImg;
	add.s64 	%rd69, %rd68, %rd85;
	ld.shared.f32 	%f85, [%rd69];
	ld.shared.f32 	%f86, [%rd67];
	sub.f32 	%f87, %f86, %f85;
	mul.f32 	%f88, %f87, %f87;
	ld.const.f32 	%f89, [%rd86+32];
	fma.rn.f32 	%f90, %f89, %f88, %f142;
	ld.shared.f32 	%f91, [%rd69+4];
	ld.shared.f32 	%f92, [%rd67+4];
	sub.f32 	%f93, %f92, %f91;
	mul.f32 	%f94, %f93, %f93;
	ld.const.f32 	%f95, [%rd86+60];
	fma.rn.f32 	%f96, %f95, %f94, %f90;
	ld.shared.f32 	%f97, [%rd69+8];
	ld.shared.f32 	%f98, [%rd67+8];
	sub.f32 	%f99, %f98, %f97;
	mul.f32 	%f100, %f99, %f99;
	ld.const.f32 	%f101, [%rd86+88];
	fma.rn.f32 	%f102, %f101, %f100, %f96;
	ld.shared.f32 	%f103, [%rd69+12];
	ld.shared.f32 	%f104, [%rd67+12];
	sub.f32 	%f105, %f104, %f103;
	mul.f32 	%f106, %f105, %f105;
	ld.const.f32 	%f107, [%rd86+116];
	fma.rn.f32 	%f108, %f107, %f106, %f102;
	ld.shared.f32 	%f109, [%rd69+16];
	ld.shared.f32 	%f110, [%rd67+16];
	sub.f32 	%f111, %f110, %f109;
	mul.f32 	%f112, %f111, %f111;
	ld.const.f32 	%f113, [%rd86+144];
	fma.rn.f32 	%f142, %f113, %f112, %f108;
	add.s64 	%rd86, %rd86, 4;
	add.s32 	%r25, %r23, 1;
	add.s64 	%rd85, %rd85, 80;
	add.s32 	%r95, %r95, 1;
	setp.ne.s32	%p18, %r95, 0;
	mov.u32 	%r93, %r25;
	@%p18 bra 	BB0_24;

	neg.f32 	%f116, %f142;
	div.rn.f32 	%f117, %f116, %f32;
	mul.f32 	%f118, %f117, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f119, %f118;
	fma.rn.f32 	%f121, %f119, %f73, %f117;
	fma.rn.f32 	%f123, %f119, %f75, %f121;
	mul.f32 	%f115, %f123, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f114,%f115;
	// inline asm
	add.f32 	%f124, %f119, 0f00000000;
	ex2.approx.f32 	%f125, %f124;
	mul.f32 	%f126, %f114, %f125;
	setp.lt.f32	%p19, %f117, 0fC2D20000;
	selp.f32	%f127, 0f00000000, %f126, %p19;
	setp.gt.f32	%p20, %f117, 0f42D20000;
	selp.f32	%f128, 0f7F800000, %f127, %p20;
	setp.neu.f32	%p21, %f128, 0f3F800000;
	setp.lt.f32	%p22, %f139, %f128;
	and.pred  	%p23, %p21, %p22;
	selp.f32	%f139, %f128, %f139, %p23;
	add.f32 	%f141, %f128, %f141;
	mul.lo.s64 	%rd70, %rd9, 80;
	add.s64 	%rd72, %rd68, %rd70;
	shl.b64 	%rd73, %rd11, 2;
	add.s64 	%rd74, %rd72, %rd73;
	ld.shared.f32 	%f129, [%rd74];
	fma.rn.f32 	%f140, %f128, %f129, %f140;
	setp.lt.s32	%p24, %r22, 16;
	mov.u32 	%r90, %r22;
	@%p24 bra 	BB0_23;

	add.s32 	%r91, %r91, 1;
	setp.lt.s32	%p25, %r91, 16;
	@%p25 bra 	BB0_22;

BB0_27:
	add.s16 	%rs3, %rs2, 1;
	cvt.s16.s8 	%rs8, %rs3;
	setp.lt.s16	%p26, %rs8, 4;
	mov.u16 	%rs11, %rs3;
	@%p26 bra 	BB0_16;

	add.s16 	%rs12, %rs12, 1;
	cvt.s16.s8 	%rs9, %rs12;
	setp.lt.s16	%p27, %rs9, 4;
	@%p27 bra 	BB0_15;

	shl.b32 	%r72, %r32, 10;
	add.s32 	%r75, %r34, %r72;
	mov.u32 	%r76, %tid.x;
	add.s32 	%r77, %r75, %r76;
	add.s32 	%r78, %r76, 2;
	mov.f32 	%f130, 0f3F800000;
	sub.f32 	%f131, %f130, %f139;
	mul.f32 	%f132, %f131, 0f40A00000;
	sub.f32 	%f133, %f141, %f132;
	add.s32 	%r80, %r2, 2;
	mul.wide.u32 	%rd75, %r78, 80;
	add.s64 	%rd77, %rd43, %rd75;
	mul.wide.u32 	%rd78, %r80, 4;
	add.s64 	%rd79, %rd77, %rd78;
	ld.shared.f32 	%f134, [%rd79];
	mul.f32 	%f135, %f132, %f134;
	sub.f32 	%f136, %f140, %f135;
	div.rn.f32 	%f137, %f136, %f133;
	shl.b32 	%r81, %r2, 6;
	add.s32 	%r82, %r77, %r81;
	cvta.to.global.u64 	%rd80, %rd17;
	mul.wide.u32 	%rd81, %r82, 4;
	add.s64 	%rd82, %rd80, %rd81;
	st.global.f32 	[%rd82], %f137;
	ret;
}


